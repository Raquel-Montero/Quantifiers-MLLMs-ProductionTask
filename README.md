<h1 align="center"> Quantification and Object Perception in Multimodal Large Language Models</h1>
<p align="center"><em>Raquel Montero, Natalia Moskvina, Paolo Morosi, Tamara Serrano, Elena Pagliarini and Evelina Leivada </em></p>

## About this respository
This repository contains the materials used to test how GPT-4o, o4-mini and humans use quantifiers when describing images. The study tested six different languages: English, Greek, Russian, Spanish, Italian and Catalan. For more information on the study see the paper “Quantification and object perception in multimodal large language models deviate from human linguistic cognition”. 


## Acknowledgement
We acknowledge funding from the Spanish Ministry of Science, Innovation \& Universities under the research project CNS2023-144415 (E.L.) and the European Union NextGenerationEU/PRTR, Grant RYC2021-033969-I (E.P.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
